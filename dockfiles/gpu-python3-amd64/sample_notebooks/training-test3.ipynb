{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train AlexNet with Tiny ImageNet-200\n",
    "\n",
    "We are going to train the [AlexNet](https://arxiv.org/abs/1404.5997) model to work with the [Tiny ImageNet-200](https://tiny-imagenet.herokuapp.com/), a subset of ImageNet with 200 classes.\n",
    "\n",
    "But we are not going to train it from the scratch, we are going to use the pre-trained model from [torchvision](http://pytorch.org/docs/master/torchvision/models.html), stripping the last layer and replacing it by a fresh layer that outputs 200 units instead of the original 1000 units for ImageNet. The last layer is the one we are going to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some constants for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"datasets/tiny-imagenet-200/\"\n",
    "num_classes = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and pre-processing\n",
    "\n",
    "First we load and pre-process the data according to the pre-trained model [documentation](http://pytorch.org/docs/master/torchvision/models.html), applying transformations using [this example](https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L113).\n",
    "\n",
    "For training data, we resize and crop randomly to get images of 224x224, flip horizontally some of the images, transform them to a tensor and finally normalize them to have values between 0 and 1. The magic normalization parameters come from the example.\n",
    "\n",
    "For the validation data we use less corrupted images, only resizing them and cropping them in the center and then appliying the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# modify this depending on memory constraints\n",
    "batch_size = 64\n",
    "\n",
    "# the magic normalization parameters come from the example\n",
    "transform_mean = np.array([ 0.485, 0.456, 0.406 ])\n",
    "transform_std = np.array([ 0.229, 0.224, 0.225 ])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = transform_mean, std = transform_std),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = transform_mean, std = transform_std),\n",
    "])\n",
    "\n",
    "traindir = os.path.join(directory, \"train\")\n",
    "# be careful with this set, the labels are not defined using the directory structure\n",
    "valdir = os.path.join(directory, \"val\")\n",
    "\n",
    "train = datasets.ImageFolder(traindir, train_transform)\n",
    "val = datasets.ImageFolder(valdir, val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "assert num_classes == len(train_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loader.__iter__().__next__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label madness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WordNet](https://wordnet.princeton.edu/) is a large lexical database of English. ImageNet uses a subset of this database as labels for the images, and the Tiny ImageNet-200 uses an even smaller subset. The Tiny ImageNet-200 comes with a map between WordNet ids and WordNet definitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_labels = {}\n",
    "with open(os.path.join(directory, \"words.txt\"), \"r\") as dictionary_file:\n",
    "    line = dictionary_file.readline()\n",
    "    while line:\n",
    "        label_id, label = line.strip().split(\"\\t\")\n",
    "        small_labels[label_id] = label\n",
    "        line = dictionary_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(small_labels.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train subdirectory of Tiny ImageNet-200 has a collection of subdirectories, named using to the WordNet ids to label the images that they contain. The torchvision data loader uses the names of the subdirectories as labels, but replaces them with numeric indices when iterating the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(traindir)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "label_ids = {}\n",
    "for label_index, label_id in enumerate(train_loader.dataset.classes):\n",
    "    label = small_labels[label_id]\n",
    "    labels[label_index] = label\n",
    "    label_ids[label_id] = label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(label_ids.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem is that the validation directory only has one subdirectory called `images`. The labels for every image inside this subdirectory are defined in a file called `val_annotations.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_map = {}\n",
    "with open(os.path.join(directory, \"val/val_annotations.txt\"), \"r\") as val_label_file:\n",
    "    line = val_label_file.readline()\n",
    "    while line:\n",
    "        file_name, label_id, _, _, _, _ = line.strip().split(\"\\t\")\n",
    "        val_label_map[file_name] = label_id\n",
    "        line = val_label_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(val_label_map.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we update the Tiny ImageNet-200 validation set labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader.dataset.imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_loader.dataset.imgs)):\n",
    "    file_path = val_loader.dataset.imgs[i][0]\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    label_id = val_label_map[file_name]\n",
    "    \n",
    "    val_loader.dataset.imgs[i] = (file_path, label_ids[label_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader.dataset.imgs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier weight initialization for the extra layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    weight_shape = list(m.weight.data.size())\n",
    "    fan_in = weight_shape[1]\n",
    "    fan_out = weight_shape[0]\n",
    "    w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "    m.weight.data.uniform_(-w_bound, w_bound)\n",
    "    m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained error, get the weights and remove the last lawer parameters.\n",
    "\n",
    "Create an empty model with the desired last layer size, copy the parameters and initialize the rest.\n",
    "\n",
    "Note that only the new parameters will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = models.alexnet(pretrained=True)\n",
    "state_dict = pre_trained_model.state_dict()\n",
    "state_dict.pop(\"classifier.6.weight\")\n",
    "state_dict.pop(\"classifier.6.bias\")\n",
    "model = models.alexnet(num_classes=num_classes)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# parameters = model.classifier[6].parameters()\n",
    "parameters = list(model.classifier[6].parameters())\n",
    "initialize_weights(model.classifier[6])\n",
    "\n",
    "model = model.cpu()\n",
    "# model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(parameters, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the percentage of error in the top-k most probable classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:RaftLog3:Confirm committed: dbfc7dbd-2991-4959-b813-ad80dacc5e2c\n"
     ]
    }
   ],
   "source": [
    "def top_k_error(top_k, total):\n",
    "    return 100.0 - top_k / total * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one epoch, either with training or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def run_epoch(loader, train=True, log_every=100, max_batch=0):\n",
    "    running_loss = 0.0\n",
    "    running_top_1 = 0.0\n",
    "    running_top_5 = 0.0\n",
    "    running_total = 0.0\n",
    "    \n",
    "    epoch_top_1 = 0.0\n",
    "    epoch_top_5 = 0.0\n",
    "    epoch_total = 0.0\n",
    "    \n",
    "    model.train(mode=train)\n",
    "    \n",
    "    batch_start = time.time()\n",
    "    batch_load = 0.0\n",
    "    batch_compute = 0.0\n",
    "    \n",
    "    for batch_number, (batch_inputs, batch_labels) in enumerate(loader):\n",
    "        batch_loaded = time.time()\n",
    "        batch_load += batch_loaded - batch_start\n",
    "        \n",
    "        batch_inputs, batch_labels = Variable(batch_inputs.cpu()), Variable(batch_labels.cpu())\n",
    "#         batch_inputs, batch_labels = Variable(batch_inputs.cuda()), Variable(batch_labels.cuda())\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batch_logits = model(batch_inputs)\n",
    "        \n",
    "        if train:\n",
    "            batch_loss = criterion(batch_logits, batch_labels)\n",
    "            batch_loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += batch_loss.data.cpu().item()\n",
    "            \n",
    "        batch_end = time.time()\n",
    "        batch_compute += batch_end - batch_loaded\n",
    "        \n",
    "        batch_labels = batch_labels.data.cpu().numpy()\n",
    "        batch_predictions = batch_logits.topk(5)[1].data.cpu().numpy()\n",
    "    \n",
    "        for i in range(len(batch_labels)):\n",
    "            if batch_labels[i] == batch_predictions[i, 0]:\n",
    "                running_top_1 += 1\n",
    "                running_top_5 += 1\n",
    "                epoch_top_1 += 1\n",
    "                epoch_top_5 += 1\n",
    "            else:\n",
    "                for j in range(1, 5):\n",
    "                    if batch_labels[i] == batch_predictions[i, j]:\n",
    "                        running_top_5 += 1\n",
    "                        epoch_top_5 += 1\n",
    "                        break\n",
    "        \n",
    "        running_total += len(batch_labels)\n",
    "        epoch_total += len(batch_labels)\n",
    "\n",
    "        if batch_number % log_every == log_every - 1:\n",
    "            if train:\n",
    "                print(\"[Batch {:5d}] Loss: {:.3f} Top-1 Error: {:.3f} Top-5 Error: {:.3f}, Load time: {:.3f} ms, Compute time: {:.3f} ms\".format(\n",
    "                    batch_number + 1,\n",
    "                    running_loss / log_every,\n",
    "                    top_k_error(running_top_1, running_total),\n",
    "                    top_k_error(running_top_5, running_total),\n",
    "                    batch_load * 1000 / log_every,\n",
    "                    batch_compute * 1000 / log_every,\n",
    "                ))\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_top_1 = 0.0\n",
    "            running_top_5 = 0.0\n",
    "            running_total = 0.0\n",
    "            batch_load = 0.0\n",
    "            batch_compute = 0.0\n",
    "            \n",
    "        if max_batch > 0 and batch_number >= max_batch - 1:\n",
    "            break\n",
    "            \n",
    "    return top_k_error(epoch_top_1, epoch_total), top_k_error(epoch_top_5, epoch_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch     1] Loss: inf Top-1 Error: 98.438 Top-5 Error: 96.875, Load time: 462.849 ms, Compute time: 50646.056 ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_353/2033381499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_top_1_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_top_5_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     print(\"[Epoch {:3d}] Training Top-1 Error: {:.3f} Top-5 Error: {:.3f}\".format(\n\u001b[1;32m      7\u001b[0m         epoch_number + 1, train_top_1_error, train_top_5_error))\n",
      "\u001b[0;32m/tmp/ipykernel_353/2710505866.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(loader, train, log_every, max_batch)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mbatch_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torchvision/models/alexnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1 # modify this to run different number of epochs\n",
    "\n",
    "for epoch_number in range(num_epochs):\n",
    "\n",
    "    train_top_1_error, train_top_5_error = run_epoch(train_loader, train=True, log_every=1, max_batch=10)\n",
    "    print(\"[Epoch {:3d}] Training Top-1 Error: {:.3f} Top-5 Error: {:.3f}\".format(\n",
    "        epoch_number + 1, train_top_1_error, train_top_5_error))\n",
    "    \n",
    "    val_top_1_error, val_top_5_error = run_epoch(val_loader, train=False, max_batch=10)\n",
    "    print(\"[Epoch {:3d}] Validation Top-1 Error: {:.3f} Top-5 Error: {:.3f}\".format(\n",
    "        epoch_number + 1, val_top_1_error, val_top_5_error))\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some samples\n",
    "\n",
    "To be sure that we did not mess up with the labels and see how the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train(mode=False)\n",
    "\n",
    "num_images = 10 # modify the number of images shown\n",
    "\n",
    "batch_inputs, batch_labels = next(iter(val_loader))\n",
    "with torch.no_grad():\n",
    "    batch_inputs = Variable(batch_inputs.cpu())\n",
    "# batch_inputs = Variable(batch_inputs.cuda(), volatile=True)\n",
    "\n",
    "batch_logits = model(batch_inputs)\n",
    "\n",
    "batch_labels = batch_labels.numpy()\n",
    "batch_predictions = batch_logits.topk(5)[1].data.cpu().numpy()\n",
    "\n",
    "cell_number = 1\n",
    "\n",
    "plt.figure(figsize=(4, num_images * 2))\n",
    "\n",
    "for image_number in range(num_images):\n",
    "    image = np.copy(batch_inputs.data[image_number].cpu().numpy())\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    for channel in range(3):\n",
    "        image[:, :, channel] = image[:, :, channel] * transform_std[channel] + transform_mean[channel]\n",
    "\n",
    "    label = labels[batch_labels[image_number]]\n",
    "\n",
    "    plt.subplot(num_images, 2, cell_number)\n",
    "\n",
    "    ax = plt.imshow(image)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    cell_number += 1\n",
    "\n",
    "    plt.subplot(num_images, 2, cell_number)\n",
    "    plt.axis(\"off\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0, 0.85, \"Label: {}\".format(label))\n",
    "    for prediction_number in range(5):\n",
    "        plt.text(0, 0.85 - 0.15 * (prediction_number + 1), \"Prediction-{:d}: {}\".format(\n",
    "            prediction_number + 1, labels[batch_predictions[image_number, prediction_number]]))\n",
    "    \n",
    "    cell_number += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Distrbuted Python 3",
   "language": "text",
   "name": "distributed"
  },
  "language_info": {
   "file_extension": ".txt",
   "mimetype": "text/plain",
   "name": "Any text"
  },
  "persistent_id": "6d1e4d69-3a21-4a1e-86f4-5790fe8b52ae",
  "replica_id": "3"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
