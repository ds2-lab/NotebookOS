- name: Install Hadoop HDFS
  hosts: namenode, datanodes
  remote_user: "{{ remote_username }}"
  become: true       # Run tasks as root
  gather_facts: true
  environment:
    LD_LIBRARY_PATH: "{{ python_build_dir }}/Python-{{ python_version }}:$LD_LIBRARY_PATH"
    PYTHONPATH: "$PYTHONPATH:{{ python_virtual_env_dir }}/lib64/python{{ python_short_version }}/site-packages/"
  vars:
    ansible_python_interpreter: "{{ python_virtual_env_dir }}/bin/python3.12"
    hadoop_user: "hadoop"
    hadoop_password: "12345"
    hadoop_version: "3.3.6"
    hadoop_install_dir: /opt/hadoop
    java_home: /usr/lib/jvm/java-8-openjdk-amd64
    hadoop_config_src: "{{ go_install_parent_dir }}/go/pkg/distributed-notebook/hdfs_configuration/*"
    hadoop_env_src: "{{ go_install_parent_dir }}/pkg/distributed-notebook/setup/hadoop-env"

  tasks:
    - name: Update package index and install Java and SSH
      apt:
        name:
          - openjdk-8-jdk
          - ssh
        state: present
      when: ansible_os_family == "Debian"

    - name: Download Hadoop tar.gz file
      get_url:
        url: "https://dlcdn.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
        dest: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"
        mode: '0644'

    - name: Extract Hadoop from the downloaded archive
      unarchive:
        src: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
        dest: "{{ hadoop_install_dir }}"
        remote_src: yes
        creates: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"

    - name: Create Hadoop symlink
      file:
        src: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"
        dest: "{{ hadoop_install_dir }}/hadoop"
        state: link

    - name: Set JAVA_HOME in Hadoop environment
      lineinfile:
        path: "{{ hadoop_install_dir }}/hadoop/etc/hadoop/hadoop-env.sh"
        regexp: '^export JAVA_HOME='
        line: 'export JAVA_HOME={{ java_home }}'
        state: present

    - name: Create hadoop user
      shell: 'useradd -p "$(openssl passwd -6 {{ hadoop_user_password }})" {{ hadoop_user }}'
      register: hadoop_useradd_output
      become: true
      failed_when:
        - hadoop_useradd_output.rc != 0 and hadoop_useradd_output.rc != 9 # 9 is already "username already in use"

    - name: Create Hadoop home directory and set permissions
      file:
        path: "/home/{{ hadoop_user }}"
        state: directory
        owner: "{{ hadoop_user }}"
        mode: '0777'

    - name: Create .ssh directory for hadoop user
      file:
        path: "/home/{{ hadoop_user }}/.ssh"
        state: directory
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"
        mode: '0700'

    - name: "Create SSH key for Hadoop user {{ hadoop_user }}"
      command: 'ssh-keygen -t rsa -N "" -f hadoop.key'
      args:
        chdir: "/home/{{ hadoop_user }}/.ssh"
      become: true
      become_user: {{ hadoop_user }}

#    - name: "Move SSH private SSH key for Hadoop user {{ hadoop_user }}"
#      command: "mv /home/{{ remote_username }}/hadoop.key /home/{{ hadoop_user }}/.ssh/hadoop.key"
#      become: true
#
#    - name: "Move SSH public SSH key for Hadoop user {{ hadoop_user }}"
#      command: "mv /home/{{ remote_username }}/hadoop.key.pub /home/{{ hadoop_user }}/.ssh/hadoop.key.pub"
#      become: true
#
#    - name: "Change ownership of SSH keys for Hadoop user {{ hadoop_user }}"
#      command: 'chown -R {{ hadoop_user }} /home/{{ hadoop_user }}/.ssh'
#      become: true

#    - name: Set ownership for Hadoop installation directory
#      file:
#        path: "/home/{{ hadoop_user }}/hadoop"
#        state: directory
#        owner: "{{ hadoop_user }}"
#        group: "{{ hadoop_user }}"
#        recurse: yes
#        mode: 0755
#
#    - name: Ensure /home/{{ hadoop_user }}/hadoopdata/namenode directory exists
#      file:
#        path: "/home/{{ hadoop_user }}/hadoopdata/namenode"
#        state: directory
#        owner: "{{ hadoop_user }}"
#        group: "{{ hadoop_user }}"
#        mode: 0755
#
#    - name: Ensure /home/{{ hadoop_user }}/hadoopdata/datanode directory exists
#      file:
#        path: "/home/{{ hadoop_user }}/hadoopdata/datanode"
#        state: directory
#        owner: "{{ hadoop_user }}"
#        group: "{{ hadoop_user }}"
#        mode: 0755

#    - name: Set Hadoop environment variables
#      copy:
#        src: "{{ hadoop_env_src }}"
#        dest: "{{ hadoop_install_dir }}/hadoop/etc/hadoop/hadoop-env.sh"
#        owner: "{{ hadoop_user }}"
#        group: "{{ hadoop_user }}"
#        mode: '0644'
#
#    - name: Copy HDFS configuration
#      copy:
#        src: "{{ hadoop_config_src }}"
#        dest: "{{ hadoop_install_dir }}/hadoop/etc/hadoop/"
#        owner: "{{ hadoop_user }}"
#        group: "{{ hadoop_user }}"
#        mode: '0644'
#
#    - name: Format HDFS
#      become: yes
#      become_user: "{{ hadoop_user }}"
#      command: "env JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 /home/hadoop/hadoop/bin/hdfs namenode -format"
