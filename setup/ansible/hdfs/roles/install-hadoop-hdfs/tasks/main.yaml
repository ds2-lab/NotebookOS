- name: Update package index and install Java and SSH
  apt:
    name:
      - openjdk-8-jdk
      - ssh
    state: present
  when: ansible_os_family == "Debian"

- name: Create hadoop user
  shell: 'useradd -p "$(openssl passwd -6 {{ hadoop_password }})" {{ hadoop_user }}'
  register: hadoop_useradd_output
  become: true
  failed_when:
    - hadoop_useradd_output.rc != 0 and hadoop_useradd_output.rc != 9 # 9 is already "username already in use"

- name: Create Hadoop home directory and set permissions
  file:
    path: "/home/{{ hadoop_user }}"
    state: directory
    owner: "{{ hadoop_user }}"
    mode: '0777'

- name: Create .ssh directory for hadoop user
  file:
    path: "/home/{{ hadoop_user }}/.ssh"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    mode: '0700'
  become: true

- name: Create SSH key for Hadoop user {{ hadoop_user }}
  command: ssh-keygen -t rsa -b 2048 -N "" -f /home/{{ hadoop_user }}/.ssh/hadoop.key
  become: true
  become_user: "{{ hadoop_user }}"
  args:
    creates: "/home/{{ hadoop_user }}/.ssh/hadoop.key"

- name: Set ownership and permissions on SSH key for Hadoop user
  file:
    path: "/home/{{ hadoop_user }}/.ssh/hadoop.key"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    mode: 0600
  become: true

- name: Set ownership and permissions on SSH key for Hadoop user
  file:
    path: "/home/{{ hadoop_user }}/.ssh/hadoop.key.pub"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    mode: 0600
  become: true

- name: Download Hadoop tar.gz file
  get_url:
    url: "https://dlcdn.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    mode: '0644'

- name: Extract Hadoop from the downloaded archive
  unarchive:
    src: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "{{ hadoop_unarchive_dir }}"
    remote_src: yes
    creates: "{{ hadoop_unarchive_dir }}/hadoop-{{ hadoop_version }}"

- name: Create Hadoop symlink
  file:
    src: "{{ hadoop_unarchive_dir }}/hadoop-{{ hadoop_version }}"
    dest: "{{ hadoop_unarchive_dir }}/hadoop"
    state: link

- name: "Ensure that the {{ hadoop_hdfs_home_dir }} directory exists and belongs to the Hadoop user {{ hadoop_user }}"
  file:
    path: "{{ hadoop_hdfs_home_dir }}"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    recurse: true
    mode: 0700
  become: true

- name: Set JAVA_HOME in Hadoop environment
  lineinfile:
    path: "{{ hadoop_unarchive_dir }}/hadoop/etc/hadoop/hadoop-env.sh"
    regexp: '^export JAVA_HOME='
    line: 'export JAVA_HOME={{ java_home }}'
    state: present

- name: Create the hadoop HDFS log directory
  ansible.builtin.file:
    path: '{{ hadoop_hdfs_log_dir }}'
    state: directory
    group: '{{ hadoop_user }}'
    owner: '{{ hadoop_user }}'
    mode: 0755
  become: true
  tags:
    - zookeeper_dirs

- name: Create/copy the core-site.xml configuration file.
  template:
    src: core-site.xml.j2
    dest: "{{ hadoop_hdfs_conf_dir }}/core-site.xml"
    mode: 0640

- name: Create/copy the hadoop-env.sh configuration file.
  template:
    src: hadoop-env.sh.j2
    dest: "{{ hadoop_hdfs_conf_dir }}/hadoop-env.sh"
    mode: 0640

- name: Create/copy the hdfs-site.xml configuration file.
  template:
    src: hdfs-site.xml.j2
    dest: "{{ hadoop_hdfs_conf_dir }}/hdfs-site.xml"
    mode: 0640

- name: Create/copy the hosts configuration file.
  template:
    src: hosts.j2
    dest: /etc/hosts
    mode: 0777
  become: true

- name: Update and upgrade apt packages on all VMs.
  apt:
    upgrade: yes
    update_cache: yes

- name: Copy the configured private key to the remote hosts for the standard user
  copy:
    src: "{{ private_key_to_upload }}"
    remote_src: false
    dest: "/home/{{ remote_username }}/.ssh/id_rsa"
    owner: "{{ remote_username }}"
    group: "{{ remote_username }}"
    mode: 0600

- name: Copy the configured public key to the remote hosts for the standard user
  copy:
    src: "{{ public_key_to_upload }}"
    remote_src: false
    dest: "/home/{{ remote_username }}/.ssh/id_rsa.pub"
    owner: "{{ remote_username }}"
    group: "{{ remote_username }}"
    mode: 0600

- name: "Copy the configured private key to the remote hosts for the {{ hadoop_user }} user"
  copy:
    src: "{{ private_key_to_upload }}"
    remote_src: false
    dest: "/home/{{ hadoop_user }}/.ssh/id_rsa"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    mode: 0600
  become: true

- name: "Copy the configured public key to the remote hosts for the {{ hadoop_user }} user"
  copy:
    src: "{{ public_key_to_upload }}"
    remote_src: false
    dest: "/home/{{ hadoop_user }}/.ssh/id_rsa.pub"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    mode: 0600
  become: true

- name: "Ensure that the copied private key will work for SSHing between the hosts for the standard user"
  shell: "cat /home/{{ remote_username }}/.ssh/id_rsa.pub >> /home/{{ remote_username }}/.ssh/authorized_hosts"

- name: "Ensure that the copied private key will work for SSHing between the hosts for the {{ hadoop_user }} user"
  shell: "cat /home/{{ hadoop_user }}/.ssh/id_rsa.pub >> /home/{{ hadoop_user }}/.ssh/authorized_hosts"