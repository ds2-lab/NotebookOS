global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 15s
alerting:
  alertmanagers:
    - static_configs:
        - targets: [ ]
      scheme: http
      timeout: 10s
      api_version: v2
scrape_configs:
  # Scrape the node-exporter containers
  - job_name: 'node-exporter'
    dns_sd_configs:
      - names:
          - node-exporter
        type: A
        port: {{ node_exporter_port }}

  # Scrape the cadvisor containers
  - job_name: 'cadvisor'
    dns_sd_configs:
      - names:
          - cadvisor
        type: A
        port: {{ cadvisor_port }}

  # Scraping Prometheus' own metrics
  - job_name: 'prometheus'
    scrape_interval: 5s
    static_configs:
      - targets: ['prometheus:8500']

  # Create a job for Docker daemons.
  - job_name: 'docker'
    dockerswarm_sd_configs:
      - host: unix:///var/run/docker.sock
        role: nodes
    relabel_configs:
      # Fetch metrics on port 9323.
      - source_labels: [__meta_dockerswarm_node_address]
        target_label: __address__
        replacement: $1:9323
      # Set hostname as instance label
      - source_labels: [__meta_dockerswarm_node_hostname]
        target_label: instance

  # Scrape Docker Swarm services via service discovery
  - job_name: 'docker-swarm'
    dockerswarm_sd_configs:
        # We could use HTTP/HTTPS/TCP instead, if desired, by passing the following "host" parameter:
        # "tcp://{{ hostvars['swarm-leader'].ansible_default_ipv4.address|default(hostvars['swarm-leader'].ansible_all_ipv4_addresses[0]) }}:2375"
      - host: "unix:///var/run/docker.sock"
        role: 'tasks'  # Discover containers
    relabel_configs:
      # Only scrape containers in the traefik-public network.
      - source_labels: [__meta_dockerswarm_network_name]
        regex: 'traefik-public'
        action: keep
      # Only scrape containers with the label "app=kernel_replica" or "app=distributed_cluster"
      - source_labels: [__meta_dockerswarm_container_label_app]
        regex: 'kernel_replica|distributed_cluster'
        action: keep
      # Only scrape containers if they have a "prometheus-metrics-provider=true" label.
      - source_labels: [__meta_dockerswarm_container_label_prometheus_metrics_provider]
        regex: 'true'
        action: keep
      # Replace the __address__ with the container's address followed by ":<port>", where
      # <port> is the value of the "prometheus.metrics.port" label.
      - source_labels: [__address__, __meta_dockerswarm_container_label_prometheus_metrics_port]
        regex: '(.*):(\d+);(\d+)'
        target_label: __address__
        replacement: "$1:$3"
      # If the container also has a "prometheus.metrics.basepath" label, then append that to the end
      # of the __address__. This is relevant for the Jupyter Server, whose base path has been changed
      # to /jupyter, and so Prometheus needs to scrape "<jupyter container ip>:8888/jupyter/metrics",
      # rather than "<jupyter container ip>:8888/metrics"
      - source_labels: [__address__, __meta_dockerswarm_container_label_prometheus_metrics_basepath]
        regex: '(.+);(.+)'
        target_label: __address__
        replacement: '$1$2'
        action: replace
