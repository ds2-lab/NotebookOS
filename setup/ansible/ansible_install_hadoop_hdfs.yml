- name: Install Hadoop HDFS
  hosts: vms
  remote_user: "{{ remote_username }}"
  become: true       # Run tasks as root
  gather_facts: true
  environment:
    LD_LIBRARY_PATH: "{{ python_build_dir }}/Python-{{ python_version }}:$LD_LIBRARY_PATH"
    PYTHONPATH: "$PYTHONPATH:{{ python_virtual_env_dir }}/lib64/python{{ python_short_version }}/site-packages/"
  vars:
    ansible_python_interpreter: "{{ python_virtual_env_dir }}/bin/python3.12"

  tasks:
    - name: Update package index and install Java and SSH
      apt:
        name:
          - openjdk-8-jdk
          - ssh
        state: present
      when: ansible_os_family == "Debian"

    - name: Create hadoop user
      shell: 'useradd -p "$(openssl passwd -6 {{ hadoop_user_password }})" {{ hadoop_user }}'
      register: hadoop_useradd_output
      become: true
      failed_when:
        - hadoop_useradd_output.rc != 0 and hadoop_useradd_output.rc != 9 # 9 is already "username already in use"

    - name: Create Hadoop home directory and set permissions
      file:
        path: "{{ hadoop_install_dir }}"
        state: directory
        owner: "{{ hadoop_user }}"
        mode: '0777'

    - name: Create .ssh directory for hadoop user
      file:
        path: "{{ hadoop_install_dir }}/.ssh"
        state: directory
        owner: "{{ hadoop_user }}"
        mode: '0700'

    - name: "Create SSH key for Hadoop user {{ hadoop_user }}"
      command: 'ssh-keygen -t rsa -N "" -f hadoop.key'
      args:
        chdir: "/home/{{ remote_username }}"
      become: true

    - name: "Move SSH private SSH key for Hadoop user {{ hadoop_user }}"
      command: "mv /home/{{ remote_username }}/hadoop.key /home/{{ hadoop_user }}/.ssh/hadoop.key"
      become: true

    - name: "Move SSH public SSH key for Hadoop user {{ hadoop_user }}"
      command: "mv /home/{{ remote_username }}/hadoop.key.pub/home/{{ hadoop_user }}/.ssh/hadoop.key.pub"
      become: true

    - name: "Change ownership of SSH keys for Hadoop user {{ hadoop_user }}"
      command: 'chown -R {{ hadoop_user }} /home/{{ hadoop_user }}/.ssh'
      become: true

    - name: Download and extract Hadoop
      become: yes
      become_user: "{{ hadoop_user }}"
      command: >
        bash -c "wget https://dlcdn.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz &&
                  tar -xvzf hadoop-{{ hadoop_version }}.tar.gz &&
                  mv hadoop-{{ hadoop_version }} hadoop &&
                  mkdir -p ~/hadoopdata/hdfs/{namenode,datanode}"
      args:
        chdir: "/home/{{ hadoop_user }}"

    - name: Set environment variables
      blockinfile:
        path: "/home/{{ hadoop_user }}/.bashrc"
        block: |
          export HADOOP_HOME={{ hadoop_install_dir }}/hadoop
          export PATH=$PATH:$HADOOP_HOME/bin
      when: ansible_os_family == "Debian"

    - name: Set Hadoop environment variables
      copy:
        src: "{{ hadoop_env_src }}"
        dest: "{{ hadoop_install_dir }}/hadoop/etc/hadoop/hadoop-env.sh"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"
        mode: '0644'

    - name: Copy HDFS configuration
      copy:
        src: "{{ hadoop_config_src }}"
        dest: "{{ hadoop_install_dir }}/hadoop/etc/hadoop/"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_user }}"
        mode: '0644'

    - name: Format HDFS
      become: yes
      become_user: "{{ hadoop_user }}"
      command: >
        bash -c "env JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 ~/hadoop/bin/hdfs namenode -format"
